{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/abhis/Downloads/soil/new1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537    C:\\Users\\abhis\\Downloads\\Plants NPK-20240830T1...\n",
       "538    C:\\Users\\abhis\\Downloads\\Plants NPK-20240830T1...\n",
       "539    C:\\Users\\abhis\\Downloads\\Plants NPK-20240830T1...\n",
       "540    C:\\Users\\abhis\\Downloads\\Plants NPK-20240830T1...\n",
       "541    C:\\Users\\abhis\\Downloads\\Plants NPK-20240830T1...\n",
       "Name: image_path, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows from 391 to the last have been removed successfully.\n"
     ]
    }
   ],
   "source": [
    "data = data.iloc[:390]\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "data.to_csv(\"updated_dataset.csv\", index=False)  # You can choose to overwrite the original file or create a new one\n",
    "\n",
    "print(\"Rows from 391 to the last have been removed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_path', 'Nitrogen', 'Potassium', 'Phosphorus'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)  # Check the exact column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image C:\\Users\\abhis\\Downloads\\Plants NPK-20240830T173441Z-001\\Plants NPK\\healty\\image (10).jpg: [Errno 2] No such file or directory: 'C:\\\\Users\\\\abhis\\\\Downloads\\\\Plants NPK-20240830T173441Z-001\\\\Plants\\xa0NPK\\\\healty\\\\image (10).jpg'\n",
      "Data preparation completed successfully.\n",
      "Training set shape: (311, 150, 150, 3)\n",
      "Testing set shape: (78, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image_path, target_size=(150, 150)):\n",
    "    try:\n",
    "        img = load_img(image_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize the image\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Filter out invalid image paths\n",
    "valid_paths = data['image_path'].dropna().astype(str)\n",
    "\n",
    "# Initialize lists for images and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Preprocess images and filter corresponding labels\n",
    "for index, path in enumerate(valid_paths):\n",
    "    img_array = preprocess_image(path)\n",
    "    if img_array is not None:\n",
    "        X.append(img_array)\n",
    "        y.append(data.loc[index, [\"Nitrogen\", \"Potassium\", \"Phosphorus\"]].values)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Ensure X and y have the same number of samples\n",
    "assert len(X) == len(y), f\"Inconsistent samples between X ({len(X)}) and y ({len(y)})\"\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data preparation completed successfully.\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153 images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory containing the images\n",
    "image_directory = r'C:/Users/abhis/Downloads/Plants NPK-20240830T173441Z-001/Plants NPK/healty'\n",
    "\n",
    "# Get a list of all image file paths in the directory\n",
    "image_paths = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory) if filename.endswith('.jpg')]\n",
    "\n",
    "print(f\"Found {len(image_paths)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m valid_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, image_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(image_paths):\n\u001b[1;32m---> 11\u001b[0m     clean_path \u001b[38;5;241m=\u001b[39m \u001b[43mclean_file_path\u001b[49m(image_path)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# Attempt to open the image\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(clean_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the target image size (e.g., 224x224 pixels)\n",
    "# target_size = (224, 224)\n",
    "\n",
    "# valid_images = []\n",
    "# valid_labels = []\n",
    "\n",
    "# for i, image_path in enumerate(image_paths):\n",
    "#     # clean_path = clean_file_path(image_path)\n",
    "#     try:\n",
    "#         # Attempt to open the image\n",
    "#         image = cv2.imread(clean_path)\n",
    "        \n",
    "#         if image is not None:\n",
    "#             # Resize the image to the target size\n",
    "#             resized_image = cv2.resize(image, target_size)\n",
    "#             valid_images.append(resized_image)\n",
    "            \n",
    "#             # Get label for the image based on directory structure\n",
    "#             label = get_label_for_image(clean_path)\n",
    "#             valid_labels.append(label)\n",
    "#         else:\n",
    "#             print(f\"Failed to load image: {clean_path}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading image {clean_path}: {e}\")\n",
    "\n",
    "# # Convert lists to numpy arrays\n",
    "# valid_images = np.array(valid_images)\n",
    "# valid_labels = np.array(valid_labels)\n",
    "# # \n",
    "# print(f\"Successfully loaded {len(valid_images)} images.\")\n",
    "\n",
    "# # Continue with splitting data for training/testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Ensure labels and images have the same length before splitting\n",
    "# if len(valid_images) == len(valid_labels):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(valid_images, valid_labels, test_size=0.2, random_state=42)\n",
    "#     print(f\"Training set shape: {X_train.shape}\")\n",
    "#     print(f\"Testing set shape: {X_test.shape}\")\n",
    "# else:\n",
    "#     print(\"Mismatch between the number of images and labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (389, 150, 150, 3)\n",
      "Shape of y: (389, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to align images and labels\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_images \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m: valid_paths})\n\u001b[1;32m----> 3\u001b[0m df_labels \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mvalid_labels\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNitrogen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPotassium\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhosphorus\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Reset index and align\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df_images\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'valid_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# # Create a DataFrame to align images and labels\n",
    "# df_images = pd.DataFrame({'image_path': valid_paths})\n",
    "# df_labels = pd.DataFrame(valid_labels, columns=[\"Nitrogen\", \"Potassium\", \"Phosphorus\"])\n",
    "\n",
    "# # Reset index and align\n",
    "# df_images.reset_index(drop=True, inplace=True)\n",
    "# df_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Ensure the length matches\n",
    "# print(f\"Length of df_images: {len(df_images)}\")\n",
    "# print(f\"Length of df_labels: {len(df_labels)}\")\n",
    "\n",
    "# # Filter out invalid image paths\n",
    "# valid_paths = df_images['image_path'].dropna().astype(str)\n",
    "# valid_labels = df_labels.loc[df_images['image_path'].isin(valid_paths)]\n",
    "\n",
    "# # Preprocess images\n",
    "# X = []\n",
    "# for path in valid_paths:\n",
    "#     img_array = preprocess_image(path)\n",
    "#     if img_array is not None:\n",
    "#         X.append(img_array)\n",
    "\n",
    "# # Convert to numpy arrays\n",
    "# X = np.array(X)\n",
    "# y = valid_labels.values\n",
    "\n",
    "# # Check if lengths match\n",
    "# print(f\"Shape of X: {X.shape}\")\n",
    "# print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# # Proceed if lengths are consistent\n",
    "# if X.shape[0] == y.shape[0]:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#     print(\"Data preparation completed successfully.\")\n",
    "#     print(f\"Training set shape: {X_train.shape}\")\n",
    "#     print(f\"Testing set shape: {X_test.shape}\")\n",
    "# else:\n",
    "#     print(\"Error: Mismatch in number of samples between features and labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image C:\\Users\\abhis\\Downloads\\Plants NPK-20240830T173441Z-001\\Plants NPK\\healty\\image (10).jpg: [Errno 2] No such file or directory: 'C:\\\\Users\\\\abhis\\\\Downloads\\\\Plants NPK-20240830T173441Z-001\\\\Plants\\xa0NPK\\\\healty\\\\image (10).jpg'\n",
      "Shape of X: (389, 150, 150, 3)\n",
      "Shape of y: (389, 3)\n",
      "Data preparation completed successfully.\n",
      "Training set shape: (311, 150, 150, 3)\n",
      "Testing set shape: (78, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path, target_size=(150, 150)):\n",
    "    try:\n",
    "        img = load_img(image_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize the image\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Filter out invalid image paths\n",
    "valid_paths = data['image_path'].dropna().astype(str)\n",
    "valid_labels = data.loc[data['image_path'].isin(valid_paths), [\"Nitrogen\", \"Phosphorus\", \"Potassium\"]]\n",
    "\n",
    "# Preprocess images\"\n",
    "X = []\n",
    "valid_image_paths = []\n",
    "for path in valid_paths:\n",
    "    img_array = preprocess_image(path)\n",
    "    if img_array is not None:\n",
    "        X.append(img_array)\n",
    "        valid_image_paths.append(path)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = valid_labels.loc[valid_labels.index.isin([data.index[data['image_path'] == p][0] for p in valid_image_paths])].values\n",
    "\n",
    "# Check if lengths match\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# Proceed if lengths are consistent\n",
    "if X.shape[0] == y.shape[0]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"Data preparation completed successfully.\")\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Testing set shape: {X_test.shape}\")\n",
    "else:\n",
    "    print(\"Error: Mismatch in number of samples between features and labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 9s 798ms/step - loss: 368.5526 - mae: 15.9185 - val_loss: 299.2276 - val_mae: 15.8867\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 4s 585ms/step - loss: 214.9033 - mae: 12.2788 - val_loss: 141.3639 - val_mae: 8.9780\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 4s 464ms/step - loss: 177.5189 - mae: 10.8647 - val_loss: 123.1158 - val_mae: 9.2121\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 3s 429ms/step - loss: 120.8696 - mae: 8.5654 - val_loss: 124.4378 - val_mae: 8.2651\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 3s 426ms/step - loss: 133.5032 - mae: 9.0529 - val_loss: 117.5754 - val_mae: 7.6678\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 3s 417ms/step - loss: 114.2173 - mae: 8.2153 - val_loss: 102.6405 - val_mae: 7.6125\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 4s 466ms/step - loss: 110.6909 - mae: 8.1602 - val_loss: 110.1028 - val_mae: 7.9600\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 3s 424ms/step - loss: 107.1072 - mae: 8.0531 - val_loss: 76.0686 - val_mae: 6.3326\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 4s 460ms/step - loss: 92.1243 - mae: 7.4428 - val_loss: 71.1030 - val_mae: 5.8933\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 3s 421ms/step - loss: 84.5939 - mae: 7.1246 - val_loss: 74.8104 - val_mae: 6.1970\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 3s 436ms/step - loss: 83.8102 - mae: 6.9899 - val_loss: 70.6260 - val_mae: 6.1720\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 3s 414ms/step - loss: 79.6945 - mae: 6.8696 - val_loss: 77.4583 - val_mae: 6.9289\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 3s 404ms/step - loss: 78.6706 - mae: 6.7454 - val_loss: 70.9374 - val_mae: 6.2885\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 3s 419ms/step - loss: 74.3167 - mae: 6.6053 - val_loss: 76.7877 - val_mae: 6.1962\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 76.2663 - mae: 6.5715 - val_loss: 65.5893 - val_mae: 6.0331\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 4s 441ms/step - loss: 72.0863 - mae: 6.3349 - val_loss: 72.6130 - val_mae: 6.5503\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 3s 411ms/step - loss: 70.1546 - mae: 6.4750 - val_loss: 63.7323 - val_mae: 5.7391\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 3s 414ms/step - loss: 67.0877 - mae: 6.3387 - val_loss: 66.3441 - val_mae: 5.4666\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 3s 410ms/step - loss: 66.4405 - mae: 6.0696 - val_loss: 55.7049 - val_mae: 5.3073\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 3s 416ms/step - loss: 63.0664 - mae: 6.0727 - val_loss: 57.9991 - val_mae: 5.3801\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 67.9165 - mae: 5.4750\n",
      "Test Loss: 67.91650390625\n",
      "Test MAE: 5.475024700164795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Step 1: Build the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output to feed into the dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3, activation='linear'))  # Linear activation for regression output (NPK values)\n",
    "\n",
    "# Step 2: Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Step 3: Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "# Step 5: Save the model\n",
    "model.save(\"npk_prediction_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "model.save(\"npk_prediction_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Fit the datagen on your training data\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3)(x)  # Assuming 3 output values for N, P, K\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3)(x)  # Assuming 3 output values for N, P, K\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Nitrogen: 27.514970779418945\n",
      "Phosphorus: 17.88797950744629\n",
      "Potassium: 8.161398887634277\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"npk_prediction_model.h5\")\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path, target_size=(150, 150)):\n",
    "    try:\n",
    "        img = load_img(image_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize the image\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to the image you want to test\n",
    "image_path = 'C:/Users/abhis/Downloads/Plants NPK-20240830T173441Z-001/Plants NPK/Potassium/Screenshot 2024-08-30 011953.png'\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "# Check if preprocessing was successful\n",
    "if preprocessed_image is not None:\n",
    "    # Predict NPK values\n",
    "    npk_predictions = model.predict(preprocessed_image)\n",
    "\n",
    "    # Output the predictions\n",
    "    print(f\"Nitrogen: {npk_predictions[0][0]}\")\n",
    "    print(f\"Phosphorus: {npk_predictions[0][1]}\")\n",
    "    print(f\"Potassium: {npk_predictions[0][2]}\")\n",
    "else:\n",
    "    print(\"Image preprocessing failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture captured.\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "Nitrogen: 38.695594787597656\n",
      "Phosphorus: 4.717592239379883\n",
      "Potassium: 16.243682861328125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"C:/Users/abhis/Downloads/soil/npk_prediction_model.h5\")\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image_from_array(img_array, target_size=(150, 150)):\n",
    "    try:\n",
    "        img = cv2.resize(img_array, target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize the image\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Capture image from webcam with user control\n",
    "def capture_image_from_camera():\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"Could not open webcam.\")\n",
    "            return None\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()  # Capture frame from webcam\n",
    "            if not ret:\n",
    "                print(\"Failed to capture image.\")\n",
    "                break\n",
    "\n",
    "            # Show the frame to the user\n",
    "            cv2.imshow(\"Press Spacebar to Capture\", frame)\n",
    "\n",
    "            # Wait for the user to press the spacebar or 'q' to quit\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 32:  # Spacebar to capture\n",
    "                print(\"Picture captured.\")\n",
    "                break\n",
    "            elif key == ord('q'):  # 'q' to quit\n",
    "                frame = None\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return frame\n",
    "    except Exception as e:\n",
    "        print(f\"Error capturing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Capture the image\n",
    "captured_image = capture_image_from_camera()\n",
    "\n",
    "# Check if capturing was successful\n",
    "if captured_image is not None:\n",
    "    # Preprocess the captured image\n",
    "    preprocessed_image = preprocess_image_from_array(captured_image)\n",
    "    \n",
    "    if preprocessed_image is not None:\n",
    "        # Predict NPK values\n",
    "        npk_predictions = model.predict(preprocessed_image)\n",
    "\n",
    "        # Output the predictions\n",
    "        print(f\"Nitrogen: {npk_predictions[0][0]}\")\n",
    "        print(f\"Phosphorus: {npk_predictions[0][1]}\")\n",
    "        print(f\"Potassium: {npk_predictions[0][2]}\")\n",
    "    else:\n",
    "        print(\"Image preprocessing failed.\")\n",
    "else:\n",
    "    print(\"Image capture failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture captured.\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "Nitrogen: 37.14630889892578\n",
      "Phosphorus: 24.024036407470703\n",
      "Potassium: 14.037150382995605\n",
      "Fertilizer Recommendations: /nThe N value of your soil is high and might give rise to weeds. Consider the following suggestions:\n",
      "    1. Manure – adding manure can amend your soil with nitrogen.\n",
      "    2. Coffee grinds – rich in nitrogen, they can help nourish your soil.\n",
      "    3. Plant nitrogen-fixing plants like peas, beans, and soybeans./nThe P value of your soil is high. Consider the following suggestions:\n",
      "    1. Avoid adding manure as it contains high phosphorus levels.\n",
      "    2. Use phosphorus-free fertilizer.\n",
      "    3. Water your soil liberally to help remove phosphorus.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"npk_prediction_model.h5\")\n",
    "\n",
    "# Fertilizer suggestions\n",
    "fertilizer_dic = {\n",
    "    'NHigh': \"\"\"The N value of your soil is high and might give rise to weeds. Consider the following suggestions:\n",
    "    1. Manure – adding manure can amend your soil with nitrogen.\n",
    "    2. Coffee grinds – rich in nitrogen, they can help nourish your soil.\n",
    "    3. Plant nitrogen-fixing plants like peas, beans, and soybeans.\"\"\",\n",
    "    \n",
    "    'NLow': \"\"\"The N value of your soil is low. Consider the following suggestions:\n",
    "    1. Add sawdust or woodchips to help absorb excess nitrogen.\n",
    "    2. Plant heavy nitrogen-feeding plants like tomatoes or spinach.\n",
    "    3. Water your soil thoroughly to leach nitrogen deeper into the soil.\"\"\",\n",
    "\n",
    "    'PHigh': \"\"\"The P value of your soil is high. Consider the following suggestions:\n",
    "    1. Avoid adding manure as it contains high phosphorus levels.\n",
    "    2. Use phosphorus-free fertilizer.\n",
    "    3. Water your soil liberally to help remove phosphorus.\"\"\",\n",
    "\n",
    "    'PLow': \"\"\"The P value of your soil is low. Consider the following suggestions:\n",
    "    1. Add bone meal, a fast-acting source of phosphorus.\n",
    "    2. Apply phosphorus fertilizers like 10-20-10.\n",
    "    3. Introduce organic compost or manure to your soil.\"\"\",\n",
    "\n",
    "    'KHigh': \"\"\"The K value of your soil is high. Consider the following suggestions:\n",
    "    1. Loosen the soil and water thoroughly to dissolve excess potassium.\n",
    "    2. Stop using potassium-rich commercial fertilizers.\n",
    "    3. Mix in calcium-rich materials like eggshells or soft rock phosphate.\"\"\",\n",
    "\n",
    "    'KLow': \"\"\"The K value of your soil is low. Consider the following suggestions:\n",
    "    1. Mix in muricate of potash or sulphate of potash.\n",
    "    2. Bury banana peels under the soil surface.\n",
    "    3. Use potash fertilizers as they contain high potassium values.\"\"\"\n",
    "}\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image_from_array(img_array, target_size=(150, 150)):\n",
    "    try:\n",
    "        img = cv2.resize(img_array, target_size)\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize the image\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Capture image from webcam with user control\n",
    "def capture_image_from_camera():\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"Could not open webcam.\")\n",
    "            return None\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()  # Capture frame from webcam\n",
    "            if not ret:\n",
    "                print(\"Failed to capture image.\")\n",
    "                break\n",
    "\n",
    "            # Show the frame to the user\n",
    "            cv2.imshow(\"Press Spacebar to Capture\", frame)\n",
    "\n",
    "            # Wait for the user to press the spacebar or 'q' to quit\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 32:  # Spacebar to capture\n",
    "                print(\"Picture captured.\")\n",
    "                break\n",
    "            elif key == ord('q'):  # 'q' to quit\n",
    "                frame = None\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return frame\n",
    "    except Exception as e:\n",
    "        print(f\"Error capturing image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Determine the recommendation based on NPK values\n",
    "def get_fertilizer_recommendations(nitrogen, phosphorus, potassium):\n",
    "    recommendations = []\n",
    "    \n",
    "    if nitrogen > 35:  # Example threshold\n",
    "        recommendations.append(fertilizer_dic['NHigh'])\n",
    "    elif nitrogen < 15:  # Example threshold\n",
    "        recommendations.append(fertilizer_dic['NLow'])\n",
    "    \n",
    "    if phosphorus > 20:  # Example threshold\n",
    "        recommendations.append(fertilizer_dic['PHigh'])\n",
    "    elif phosphorus < 9:  # Example threshold\n",
    "        recommendations.append(fertilizer_dic['PLow'])\n",
    "    \n",
    "    if potassium > 20:  # Example threshold\n",
    "        recommendations.append(fertilizer_dic['KHigh'])\n",
    "    elif potassium < 8:  # Example threshold\n",
    "        recommendations.append(fertilizer_dic['KLow'])\n",
    "    \n",
    "    return \"/n\".join(recommendations)\n",
    "\n",
    "# Capture the image\n",
    "captured_image = capture_image_from_camera()\n",
    "\n",
    "# Check if capturing was successful\n",
    "if captured_image is not None:\n",
    "    # Preprocess the captured image\n",
    "    preprocessed_image = preprocess_image_from_array(captured_image)\n",
    "    \n",
    "    if preprocessed_image is not None:\n",
    "        # Predict NPK values\n",
    "        npk_predictions = model.predict(preprocessed_image)\n",
    "        nitrogen, phosphorus, potassium = npk_predictions[0]\n",
    "\n",
    "        # Get fertilizer recommendations\n",
    "        recommendations = get_fertilizer_recommendations(nitrogen, phosphorus, potassium)\n",
    "\n",
    "        # Output the predictions and recommendations\n",
    "        print(f\"Nitrogen: {nitrogen}\")\n",
    "        print(f\"Phosphorus: {phosphorus}\")\n",
    "        print(f\"Potassium: {potassium}\")\n",
    "        print(f\"Fertilizer Recommendations: /n{recommendations}\")\n",
    "    else:\n",
    "        print(\"Image preprocessing failed.\")\n",
    "else:\n",
    "    print(\"Image capture failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
